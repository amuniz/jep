= JEP-0000: Data API
:toc: preamble
:toclevels: 3
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

.Metadata
[cols="2"]
|===
| JEP
| 0000

| Title
| Data API

| Sponsor
| https://github.com/amuniz[Antonio Mu√±iz]

// Use the script `set-jep-status <jep-number> <status>` to update the status.
| Status
| Not Submitted :information_source:

| Type
| Standards

| Created
| 2018-06-20
//
//
// Uncomment if there is an associated placeholder JIRA issue.
//| JIRA
//| :bulb: https://issues.jenkins-ci.org/browse/JENKINS-nnnnn[JENKINS-nnnnn] :bulb:
//
//
// Uncomment if there will be a BDFL delegate for this JEP.
//| BDFL-Delegate
//| :bulb: Link to github user page :bulb:
//
//
// Uncomment if discussion will occur in forum other than jenkinsci-dev@ mailing list.
//| Discussions-To
//| :bulb: Link to where discussion and final status announcement will occur :bulb:
//
//
// Uncomment if this JEP depends on one or more other JEPs.
//| Requires
//| :bulb: JEP-NUMBER, JEP-NUMBER... :bulb:
//
//
// Uncomment and fill if this JEP is rendered obsolete by a later JEP
//| Superseded-By
//| :bulb: JEP-NUMBER :bulb:
//
//
// Uncomment when this JEP status is set to Accepted, Rejected or Withdrawn.
//| Resolution
//| :bulb: Link to relevant post in the jenkinsci-dev@ mailing list archives :bulb:

|===


== Abstract

Jenkins does not provide a homogeneous, easy to understand and easy use external API
(through CLI and HTTP) to manage Jenkins data.

Main contributions to this problem are: **lack of a real Resources API to be exposed** (raw model objects and sometimes
just human readable text is returned nowadays), and **outdated and limited tooling** (CLI and HTTP APIs serialization
is based on Stapler and Stapler annotations).

This JEP is introducing both a new set of APIs to guide developers to write better external APIs and bringing
new tooling to easily define the Resources layer to be exposed, as well as modern ways to build an HTTP/REST API.

== Specification

Main goals:

. Isolate Model from public API: introduce a new _Resources layer_ based on new APIs (in advance the _Data API_)
that can be leveraged for any data exposure (CLI and WS initially). It brings flexibility and improved
API UX for CLI/WS users and developers.
. Model can evolve whilst keeping backward compatibility in the Resources layer and Resources can
transform, map or simplify the real model to adapt it for consumers.
. The new _Data API_ is decoupled from Jenkins CLI and/or REST endpoints: the way to expose data is not a responsibility of the data itself.
(However, this JEP also includes a proposal to expose data coming from the Data API through an HTTP API)
. API messages are versioned (note the "version" attribute in messages) for easier evolution and correct handling of breaking changes.
. Modernize Jenkins: using https://github.com/FasterXML/jackson[Jackson] instead of Stapler to define
and run serialization and http://sparkjava.com/[Spark] to define/expose the HTTP API.
. Why _Data API_? Because this JEP focuses on data access (Create, Read, Update and Delete of any Jenkins stored model
using homogeneous access regardless the public interface used for it).
. The _Data API_ will provide a mechanism to generate and parse JSON messages using `@Symbol` from the structs-plugin, so messages can look like:
```
{
  version: 1,
  data:[{
    "id": "github-key",
    "type": "sshPrivateKey"
    "scope": "GLOBAL",
    "description": "GitHub checkout key",
    "username": "john.doe",
    "privateKey": "<redacted>",
    "passphrase": "<redacted>"
  }]
}
```
Note the `type` attribute, which is defined in the resource class as:
```
@Symbol("sshPrivateKey")
public class SSHPrivateKeyResource extends APIResource
```
The `type` parameter is used for deserialization too.

Also note the "version" attribute. It is added by the API to all messages (the real message payload goes into `data`).
This version attribute can be used to handle backward incompatible changes in the API. It would be initially `version: 1`
in all messages. This attribute is handled by the API itself and will be used to accomodate potentially imcompatible changes
in the part of the message generated by the API. In other words, content under the `data` attribute (generated by extensions of the API)
is not subject to the `version` attribute.

Next image shows the components involved in a common use of the Data API.
`APIResource` represents the Resouces layer which isolates Model from data exposure APIs (HTTP, CLI, Configuration as Code, ...).
`Model` boxes represent the existing model which is using the traditional `@DataBoundConstructor` (and `@DataBoundSetters`).
`data-api-plugin` is the plugin providing the interoperability layer for consumers (it contains all needed APIs and
tooling for both sides, consumer and model).

image::components.png[Components Diagram]

Any data model is commonly higly polimorphic, and Jenkins data model is it too. A model entity (think of a `Credentials` object, for example) can have different representations depending
on the installed plugins (which can add credentials types). This polimorphism needs to reflect on the Data API endpoints, where a single endpoint
must be able to serialize any form of the base entity (an `APIResource` at this layer).
In this proposal that is handled as long as leafs elements on the model hierarchy implement `APIExportable#getDataAPI()`, so a call
to that method in the top level entity (`Credentials`, in the example) will get the actual `APIResource` mapping the child model,
then Jackson do the rest (as it introspect the object to be serialized).

=== How does this works for plugin developers?

There is a PoC using the credentials plugin in a section below. But let's see how the implementation would be in a simpler case.

Given this initial model:

```
public class MyModel {

    private String foo;

    @DataBoundConstructor
    public MyModel(String foo) {
        this.foo = foo;
    }

    public String getFoo() {
        return foo;
    }

    public void setFoo(String foo) {
        this.foo = foo;
    }

}
```

To get the model exposed as `/data/mymodel`:

```
public class MyModel implements APIExportable {

    private String foo;

    @DataBoundConstructor
    public MyModel(String foo) {
        this.foo = foo;
    }

    public String getFoo() {
        return foo;
    }

    public void setFoo(String foo) {
        this.foo = foo;
    }

    @Override
    public APIResource getDataAPI() {
        return new MyModelResource(this);
    }

    @Symbol("mymodel")
    public static final class MyModelResource extends APIResource {

        private String foo;

        MyModelResource(MyModel model) {
            foo = model.getFoo();
        }

        public String getFoo() {
            return foo;
        }
    }

    @Extension
    public static final class MyModelEndpoint extends APIEndpoint {

        @Override
        public void init() {
            get("mymodel", (req, resp) -> getAllMyModel());
        }

        private String getAllMyModel() {
            MyModelService service = ExtensionList.lookupSingleton(MyModelService.class);

            return serialize(service.getAll().stream()
                    .map(m -> m.getDataAPI())
                    .collect(Collectors.toList()));
        }
    }
}
```

So `GET JENKINS_ROOT_URL/data/mymodel` would return something like:

```
{
  version: 1,
  data: [{
    foo: "bar"
  }, {
    foo: "baz"
  }]
}
```


== Motivation

There are currently two ways to expose data outside Jenkins: CLI and HTTP API.
Both APIs do not guide developers on what to return and the tooling to implement them is obsolete and limited.
Traditionally Jenkins developers have returned a serialized form of raw Jenkins model objects. The practice has serious drawbacks:

* **Lack of flexibility in the API**: response messages are tied to the model (which is usually not suitable for external consumption).
Blue Ocean is an example, a whole new HTTP API was written because the built-in Jenkins one was not enough and there was no way to adapt it
without adapting the model too.
* **Heterogeneous data format**: there is no Java API to guide developers on what to return, so the current public CLI and HTTP API is a
mix of human readable format and XML of all colors.
* **Outdated serialization tooling**: model is serialized by Stapler and based on old and limited Stapler annotations.
* **Outdated REST API tooling**: The HTTP API is based on `hudson.model.Api` class which makes nearly impossible to write a proper REST API.

== Reasoning

There are two main design decisions here:

. **The use of a resources layer instead of relying on model objects directly**. The alternative is "status quo", keep exposing the model through Stapler
and `doXX` methods (or `getDynamic` to be able to have path parameters).
There could be an objection on the proposed resources layer: there is more code to write to expose data and sometimes resource classes will
just mirror the model.
It is true, but in exchange there is a huge gain on flexibility and maintainability (the model can be modified freely whilst keeping the external data
API compatible).
. **Modernizing the tooling to write Data APIs** (introducing SparkJava and Jackson to expose the data). SparkJava is easy to use, simple, lightweight
and it evolves in a backward compatible way (they say in the documentation). Jackson is the de-facto standard tool to serialize/deserialize JSON nowadays.
Jackson and SparkJava would be the replacement for Stapler when writing HTTP APIs.
. **Why Spark?**. There are a lot of frameworks/libraries to create HTTP web services, however, for the goal of this proposal, a lightweight framework
seems to fit better than others (thinking about Jersey, for example):
.. SparkJava does not do any classpath scanning to build up the routes, so it works isolatedly based on a series of static calls from plugins code.
This will avoid potential issues with the "not-so-standard" Jenkins class loader model (and the `JenkinsRule` way of testing).
.. SparkJava only needs an additional servlet filter to get into the play (which can be defined using already existent Jenkins extension points, see
https://github.com/amuniz/credentials-plugin/blob/data-api/src/main/java/com/cloudbees/plugins/credentials/api/endpoint/SparkFilter.java[SparkFilter.java]
which is the only code needed to get SparkJava working in Jenkins).
.. Docs explicitly say "Spark is always backwards compatible", which is quite important if we build an API on top of it.
.. Routes are defined statically on startup (as opposite to annotations-based), so it allows the new API to easily perform checks on possible
duplicated/overlapping routes coming from different plugins.
.. SparkJava API is consistent, simple, understandable, and flexible for handling requests, responses and filters. Perfect for the size of
HTTP APIs defined by Jenkins plugins.
.. SparkJava does not define nor it's coupled to any serialization/deserialization library which could clash with Jenkins (ie. JAXB, which is the default
for Jersey).

Note that **migrating all existent HTTP API and CLI endpoints is not the goal of this JEP**.
This proposal is about providing and supporting a new way to expose data in Jenkins, to be used on new developments and **eventually migrate** existing
endpoints. So the existent HTTP API and CLI commands will coexist with the ones using this new API (which will be exposed under some specific
path for HTTP).

=== What about core model objects?

Ideally most of the new code should go into a new plugin (data-api-plugin), however some new interfaces will need to be created
in core in order to adapt core model objects in a way that extensions of that model can benefit of the new data-api features.

For example, `JobProperty` would need to extend `APIExportable` so any subclass of it can be properly serialized by
the data-api harness (as long as the subclass implements `APIExportable#getDataAPI()`).

To keep this change as isolated as possible from core, general endpoints (like `/data/jobs`, or `/data/job/my-job/runs`) which semantically
belong to core can be defined by the data-api-plugin itself, making use of the adapted model and new `APIResource`s in core.

== Backwards Compatibility

There are no backwards compatibility concerns related to this proposal.
Those model objects not implementing `APIExportable` will be just ignored (so they won't be included in data messages).

== Security

There are no security risks related to this proposal.
HTTP endpoints access control can be handled as it has been traditionally in Jenkins (using `hasPermissions` and `checkPermissions` methods).

== Infrastructure Requirements

There are no new infrastructure requirements related to this proposal.

== Testing

There are no testing issues related to this proposal.

== Prototype Implementation

A PoC has been written using the `credentials-plugin` and its extension `ssh-credentials-plugin`.

Note that the `api` package in `credentials` would be finally placed under the new `data-api-plugin`.

* https://github.com/amuniz/credentials-plugin/pull/1[Credentials PoC]
* https://github.com/amuniz/ssh-credentials-plugin/pull/1[SSH Credentials PoC]

== References

N/A.
